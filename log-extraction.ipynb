{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ade-joshe/Library/Python/3.12/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ade-joshe/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed log saved to: extracted/openstack_test_extracted.csv\n",
      "Processed log saved to: extracted/openstack_train_extracted.csv\n",
      "Processed log saved to: extracted/openstack_predict_extracted.csv\n"
     ]
    }
   ],
   "source": [
    "# Extract different logs.\n",
    "\n",
    "# Grab the datasets\n",
    "log_files = [\n",
    "    'raw/openstack_test.log',\n",
    "    'raw/openstack_train.log',\n",
    "    'raw/openstack_predict.log'\n",
    "]\n",
    "\n",
    "log_pattern = re.compile(\n",
    "    r\"(?P<timestamp>\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2}\\.\\d+)\\s+\"  # Matches the timestamp\n",
    "    r\"\\d+\\s+\"                                                      # Process ID (ignored for now)\n",
    "    r\"(?P<log_level>[A-Z]+)\\s+\"                                    # Matches the log level\n",
    "    r\"(?P<source>[^\\s]+)\\s+\"                                       # Matches the source\n",
    "    r\"(?:.*?req-(?P<request_id>[a-f0-9\\-]+)\\s+(?P<user_id>[a-f0-9\\-]+)\\s+(?P<project_id>[a-f0-9\\-]+)\\s+)?\" # Captures request_id, user_id, project_id\n",
    "    r\"(?:.*?\\s+(?P<internal_ip>\\b(?:[0-9]{1,3}\\.){3}[0-9]{1,3}\\b))?\" # Matches internal_ip\n",
    "    r\"(?:.*?\\\"(?P<request>[^\\\"]+)\\\")?\\s*\"                          # matches the request\n",
    "    r\"(?:status:\\s+(?P<status_code>\\d+))?\"                         # Optionally matches the status code\n",
    "    r\"(?:.*?len:\\s+(?P<response_length>\\d+))?\\s*\"                  # matches response length\n",
    "    r\"(?:.*?time:\\s+(?P<response_time_api>[0-9\\.]+))?\"             # Matches API response time\n",
    "    r\"(?:.*?Took\\s+(?P<response_time_compute>[0-9\\.]+)\\s+seconds)?\"  # Matches compute response time\n",
    ")\n",
    "\n",
    "# Function to process each line of the log\n",
    "def process_line(line):\n",
    "    match = log_pattern.search(line)\n",
    "    if match:\n",
    "        data = match.groupdict()\n",
    "        \n",
    "        # Merge both response times into a single field\n",
    "        data[\"response_time\"] = data[\"response_time_api\"] or data[\"response_time_compute\"]\n",
    "        \n",
    "        # Remove intermediate response time fields\n",
    "        del data[\"response_time_api\"]\n",
    "        del data[\"response_time_compute\"]\n",
    "        return data\n",
    "    \n",
    "    return {\n",
    "        \"timestamp\": None, \"log_level\": None, \"source\": None, \"request_id\": None,\n",
    "        \"user_id\": None, \"project_id\": None,\n",
    "        \"request\": None, \"status_code\": None,\"response_length\": None,\n",
    "        \"response_time\": None,\n",
    "        \"internal_ip\": None, \n",
    "    }  # Return None for unmatched lines\n",
    "\n",
    "\n",
    "# Parse logs to DataFrame\n",
    "def parse_logs_to_dataframe(file_path, output_dir = 'extracted'):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    results = [process_line(line) for line in lines]\n",
    "     \n",
    "    file_name = os.path.basename(file_path)\n",
    "    output_file = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}_extracted.csv\")\n",
    "    \n",
    "    # Parse logs to DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Processed log saved to: {output_file}\")\n",
    "        \n",
    "# Main script execution\n",
    "if __name__ == \"__main__\":\n",
    "    for log_file in log_files:\n",
    "        parse_logs_to_dataframe(log_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
